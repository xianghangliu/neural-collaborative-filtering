{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gmf import GMFEngine, GMF\n",
    "from mlp import MLPEngine\n",
    "from neumf import NeuMFEngine\n",
    "from data import SampleGenerator\n",
    "from metrics import MetronAtK\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def evaluate_hit_ndcg(model, evaluate_data):    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_users, test_items = evaluate_data[0], evaluate_data[1]\n",
    "        negative_users, negative_items = evaluate_data[2], evaluate_data[3]        \n",
    "        test_scores = model(test_users, test_items)\n",
    "        negative_scores = model(negative_users, negative_items)\n",
    "        \n",
    "        metron = MetronAtK(top_k=10)\n",
    "        \n",
    "        metron.subjects = [test_users.data.view(-1).tolist(),\n",
    "                             test_items.data.view(-1).tolist(),\n",
    "                             test_scores.data.view(-1).tolist(),\n",
    "                             negative_users.data.view(-1).tolist(),\n",
    "                             negative_items.data.view(-1).tolist(),\n",
    "                             negative_scores.data.view(-1).tolist()]\n",
    "    hit_ratio, ndcg = metron.cal_hit_ratio(), metron.cal_ndcg()\n",
    "        \n",
    "    \n",
    "    return hit_ratio, ndcg\n",
    "\n",
    "\n",
    "def eval_ce_loss(model, data_loader):\n",
    "    total_loss = 0.0\n",
    "    n_batches = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            users, items, ratings = batch[0], batch[1], batch[2]\n",
    "            ratings = ratings.float()\n",
    "            ratings_pred = model(users, items)\n",
    "            crit = torch.nn.BCELoss()\n",
    "            loss = crit(ratings_pred.view(-1), ratings)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            n_batches += 1\n",
    "    \n",
    "    return total_loss / n_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of userId is [0, 942]\n",
      "Range of itemId is [0, 1681]\n"
     ]
    }
   ],
   "source": [
    "ml1m_dir = 'data/ml-100k/u.data'\n",
    "ml1m_rating = pd.read_csv(ml1m_dir, sep='\\t', header=None, names=['uid', 'mid', 'rating', 'timestamp'],  engine='python')\n",
    "# Reindex\n",
    "user_id = ml1m_rating[['uid']].drop_duplicates().reindex()\n",
    "user_id['userId'] = np.arange(len(user_id))\n",
    "ml1m_rating = pd.merge(ml1m_rating, user_id, on=['uid'], how='left')\n",
    "item_id = ml1m_rating[['mid']].drop_duplicates()\n",
    "item_id['itemId'] = np.arange(len(item_id))\n",
    "ml1m_rating = pd.merge(ml1m_rating, item_id, on=['mid'], how='left')\n",
    "ml1m_rating = ml1m_rating[['userId', 'itemId', 'rating', 'timestamp']]\n",
    "print('Range of userId is [{}, {}]'.format(ml1m_rating.userId.min(), ml1m_rating.userId.max()))\n",
    "print('Range of itemId is [{}, {}]'.format(ml1m_rating.itemId.min(), ml1m_rating.itemId.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = len(ml1m_rating.userId.unique())\n",
    "num_items = len(ml1m_rating.itemId.unique())\n",
    "\n",
    "gmf_config = {'alias': 'gmf_factor8neg4-implict',\n",
    "              'num_epoch': 200,\n",
    "              'batch_size': 1024,\n",
    "              'optimizer': 'adam',\n",
    "              'adam_lr': 1e-3,\n",
    "              'num_users': num_users,\n",
    "              'num_items': num_items,\n",
    "              'latent_dim': 12,\n",
    "              'num_negative': 5,\n",
    "              'l2_regularization': 0, # 0.01\n",
    "              'use_cuda': False,\n",
    "              'device_id': 0,\n",
    "              'model_dir':'checkpoints/{}_Epoch{}_HR{:.4f}_NDCG{:.4f}.model'}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## centralised training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_generator = SampleGenerator(ratings=ml1m_rating)\n",
    "train_loader = sample_generator.instance_a_train_loader(num_negatives=gmf_config['num_negative'], \n",
    "                                                        batch_size=256)\n",
    "train_dataset = train_loader.dataset\n",
    "evaluate_data = sample_generator.evaluate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_main(model_global, train_dataset, evaluate_data):\n",
    "    opt = torch.optim.Adam(model_global.parameters(), 1e-3)\n",
    "    for epoch in range(200):\n",
    "        train_loader = sample_generator.instance_a_train_loader(num_negatives=4, batch_size=1024)\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            opt.zero_grad()\n",
    "            users, items, ratings = batch[0], batch[1], batch[2]\n",
    "            ratings = ratings.float()\n",
    "            ratings_pred = model_global(users, items)\n",
    "            crit = torch.nn.BCELoss()\n",
    "            loss = crit(ratings_pred.view(-1), ratings)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        model_global.eval()\n",
    "        hit_ratio, ndcg = evaluate_hit_ndcg(model_global, evaluate_data)\n",
    "        train_ce_loss = eval_ce_loss(model_global, train_loader)\n",
    "        if epoch % 10 == 0:\n",
    "            print(epoch, \"train_ce_loss\", train_ce_loss, \"hit_ratio\", hit_ratio, \"ndcg\", ndcg)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 train_ce_loss 0.5467866653006924 hit_ratio 0.088016967126193 ndcg 0.040109803837457436\n",
      "10 train_ce_loss 0.4965631184129676 hit_ratio 0.11558854718981973 ndcg 0.052032741536971586\n"
     ]
    }
   ],
   "source": [
    "model_c = GMF(gmf_config)\n",
    "train_main(model_c, train_dataset, evaluate_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## federated training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetSplit(Dataset):\n",
    "    def __init__(self, dataset, idxs):\n",
    "        self.dataset = dataset\n",
    "        self.idxs = list(idxs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idxs)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.dataset[self.idxs[item]]\n",
    "\n",
    "\n",
    "class LocalUpdate:\n",
    "    def __init__(self, model_global, dataset, user_id):\n",
    "        idxs = torch.where(dataset.user_tensor == user_id)[0]\n",
    "        self.local_dataset = DatasetSplit(dataset, idxs)\n",
    "        self.num_local = len(self.local_dataset)        \n",
    "        self.local_model = copy.deepcopy(model_global)\n",
    "        self.user_id = user_id\n",
    "        \n",
    "        \n",
    "    def train(self, lr, epoches_local, local_batch_size):\n",
    "        local_data_loader = DataLoader(self.local_dataset, \n",
    "                                       batch_size=local_batch_size, \n",
    "                                       shuffle=True)\n",
    "        \n",
    "        self.local_model.train()\n",
    "        opt = torch.optim.Adam(self.local_model.parameters(), lr=lr)\n",
    "        for ep_local in range(epoches_local):\n",
    "            t_loss = 0.0\n",
    "            n_batch = 0\n",
    "            for users, items, ratings in local_data_loader:\n",
    "                opt.zero_grad()\n",
    "                ratings = ratings.float()\n",
    "                ratings_pred = self.local_model(users, items).view(-1)\n",
    "                \n",
    "                crit = torch.nn.BCELoss()\n",
    "                loss = crit(ratings_pred, ratings)\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "                \n",
    "                t_loss += loss.item()\n",
    "                n_batch += 1\n",
    "            \n",
    "            if (ep_local + 1) % 100  == 0:\n",
    "                print(\"user\", self.user_id, \"ep_local\", ep_local, t_loss/n_batch)\n",
    "        \n",
    "        return t_loss/n_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fedavg(model_global, train_dataset, evaluate_data):\n",
    "    frac = 0.1\n",
    "    epoches_local = 3\n",
    "    local_lr = 1e-2\n",
    "    \n",
    "    for epoch in range(500):\n",
    "        # sample users\n",
    "        m = max(int(frac * num_users), 1)\n",
    "        idxs_users = np.random.choice(range(num_users), m, replace=False)\n",
    "\n",
    "        w_locals, n_locals = [], []\n",
    "        total_loss = 0.0\n",
    "        for idx in idxs_users:        \n",
    "            # local update\n",
    "            local_update = LocalUpdate(model_global, train_dataset, user_id=idx)\n",
    "            local_batch_size = int(len(local_update.local_dataset)*0.1)\n",
    "            total_loss += local_update.train(local_lr, epoches_local, local_batch_size=local_batch_size)\n",
    "\n",
    "            w_locals.append(copy.deepcopy(local_update.local_model.state_dict()))\n",
    "            n_locals.append(local_update.num_local)\n",
    "\n",
    "        n_locals = np.array(n_locals, dtype=np.float64)\n",
    "        n_locals /= n_locals.sum()\n",
    "\n",
    "\n",
    "        # average model\n",
    "        w_avg = {}    \n",
    "        for k in model_global.state_dict().keys():\n",
    "            w_avg[k] = 0.0\n",
    "            for i in range(len(w_locals)):\n",
    "                w_avg[k] += w_locals[i][k] * n_locals[i]\n",
    "\n",
    "        model_global.load_state_dict(w_avg)\n",
    "        hit_ratio, ndcg = evaluate_hit_ndcg(model_global, evaluate_data)\n",
    "\n",
    "        total_loss_all = eval_ce_loss(model_global, train_loader)\n",
    "        print(epoch, \"loss\", total_loss/m, total_loss_all, \"hit_ratio\", hit_ratio, \"ndcg\", ndcg)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_global = GMF(gmf_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 0.5390761853791988 0.5783632659737556 hit_ratio 0.24284199363732767 ndcg 0.11061090882636314\n",
      "1 loss 0.48633375453764505 0.5156896067887519 hit_ratio 0.22693531283138918 ndcg 0.10670224238783678\n"
     ]
    }
   ],
   "source": [
    "train_fedavg(model_global, train_dataset, evaluate_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
